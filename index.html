<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zero-shot Singing Technique Conversion</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Singing Voice Identity Embedding and Conversion</h1>
    <p id="p1">This page presents audio references to accompany the written component of my research in singing voice conversion. Audio clips presented in the same tables are intended to be compared to one another. Separate tables may be intended for isolated within-comparison, unless specified otherwise.
        The code repository that generated these audio outputs can be found at [LINK TO BE CONFIRMED]
    </p>


    <h2>Example of Disparity between Same/Cross Domain Inference</h2>

    <p>This section demonstrates what happens when a voice conversion model is entirely pretrained on one domain and attempts to convert from another domain.</p>

    <h3> Speech conversions audio outputs from AutoVC models pretrained on either singing (column 2) or speech (column 3) data.</h3>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Converted voice with singing pretraining</div>
        <div class="grid-item head">Converted voice with speech pretraining</div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p255.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p255_p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p255_p268.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p268_p255.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p268_p255.wav"></audio></div>
        
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p270.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p270_p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p270_p268.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p280.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p280_p255.wav"></audio></div>    
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p280_p255.wav"></audio></div>

    </div>

    <h3> Singing conversions audio ouputs from AutoVC models pretrained on either speech (column 2) or singing (column 3) data.</h3>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Converted voice with speech pretraining</div>
        <div class="grid-item head">Converted voice with singing pretraining</div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1174863894.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1174863894_1174863894.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1174863894_1174863894.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1143441144.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1143441144_1102104435.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1143441144_1102104435.wav"></audio></div>
        
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1141223094.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1141223094_1143441144.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1141223094_1143441144.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/p280.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1102104435_1141223094.wav"></audio></div>    
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1102104435_1141223094.wav"></audio></div>

    </div>

    <h2> Upperbound quality, as dictated by spectrogram-to-waveform synthesis process</h2>

    <p>To illustrate the upperbound limit for quality of our generated audio, the table below presents examples where audio recordings have been converted to mel spectrograms and resynthesized into audio using the pretrained Wavenet vocoder.
        This demonstrates the artefacts and deterioration due to resynthesis alone, and therefore provides an indication of the upperbound audio quality that other audio clips can be compared against for reference:</p>

    <div class="grid-container2">
        <div class="grid-item head">Original</div>
        <div class="grid-item head">Resynthesized</div>      
        <div class="grid-item"><audio controls src="1295/m9_arpeggios_straight_u_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/m9_arpeggios_straight_u_wvnt.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f2_arpeggios_straight_e_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f2_arpeggios_straight_e_wvnt.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f9_arpeggios_vocal_fry_a_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f9_arpeggios_vocal_fry_a_wvnt.mp3"></audio></div>
    </div>
    
    <h2>Spoken Voice Conversion with/without latent regressor loss</h2>

    <h3>Model condition: VCTK-BN</h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that used the bottleneck latent regressor loss,
        and was trained for 100,000 training steps on a quarter of the VCTK dataset.
        The input data was in a mel-spectrogram format.
        It was conditioned on VIEs from an encoder that was pretrained on the LibriSpeech and VoxCeleb1 datasets.
        The table shown below is arranged to present a comparison between source vocalist, target vocalist and converted voice singing clips, generated by this model:
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>

    <h3>Model: VCTK</h3>

    <p> For comparison, the audio files presented in this next table below come from an AutoVC model that was trained under the same conditions as the aforementioned model,
        but instead only used the reconstruction loss in its objective function. It can be heard from these examples, that the output audio is significantly less distorted or ambiguous in timbre.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>

    <h2> Singing Voice Conversion with Different Features</h2>

    <h3> SVC with WORLD features </h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that took WORLD spectral envelope features as input, using only reconstruction loss. The VIE encoder that was trained on the entire DAMP datasets.
        This AutoVC network was trained for 100,000 training steps on a quarter of the DAMP dataset. Here we observe conversions perceptually specific to microphone placement, loudness and room frequency reponse - but not vocal timbre.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div> 

    <h3> SVC with Mel-spectrogram features </h3>

    <p> For comparison, the audio files presented in this next table below have been generated by a model trained under the same conditions as the SVC model mentioned above, except for itst input features which were mel spectrograms.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div>

    <h3> Models trained for 500k steps </h3>

    <p> The audio files presented in the remaining two tables below have been generated by AutoVC networks that used both reconstruction and bottleneck latent regressor loss componets in their objective function.
        They were trained for 500,000 steps on a quarter of the DAMP dataset
    </p>
        
    <p> The table below presents converted audio synthesized by the model just mentioned, when trained using a VIE pretrained on the LibriSpeech and VoxCeleb1 datasets.
    </p>
    
    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F291470337_timestep1730_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F291470337_timestep1730_M475351623.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F771524047_timestep3566_F236486784_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F771524047_timestep3566_F236486784.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1654991314_timestep4850_M1473212998_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1654991314_timestep4850_M1473212998.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1473212998_timestep1822_F914688212_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1473212998_timestep1822_F914688212.wav"></audio></div>    

    </div>

    <p> The table below presents converted audio synthesized the model just mentioned, when trained using a VIE pretrained on the DAMP dataset.
    </p>
    
    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F197252304_timestep5464_M153391661_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F197252304_timestep5464_M153391661.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F265860251_timestep10056_F1705464848_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F265860251_timestep10056_F1705464848.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1224586431_timestep7530_F702021966_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1224586431_timestep7530_F702021966.wav"></audio></div>    

    </div>

</body>
</html>
