<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Singing Voice Identity Embedding and Conversion</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <h1>Singing Voice Identity Embedding and Conversion</h1>
    <p id="p1">This page presents audio references to accompany the written component of our <a href="https://arxiv.org/abs/2302.13678">paper</a> on singing voice conversion (SVC) latent regressor loss comparisons. Audio clips presented in the same tables are intended to be compared to one another. Separate tables may be intended for isolated within-comparison, unless specified otherwise.
        The code repository that generated these audio outputs can be found at [LINK TO BE CONFIRMED]
    </p>


    <h2>Example of Disparity between Same/Cross Domain Inference</h2>

    <p>This section demonstrates what happens when a voice conversion model is entirely pretrained on one domain and attempts to convert from another domain.</p>

    <h3> Speech conversions audio outputs from AutoVC models pretrained on either singing (column 2) or speech (column 3) data.</h3>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Converted voice with singing pretraining</div>
        <div class="grid-item head">Converted voice with speech pretraining</div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p255.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p255_p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p255_p268.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p268_p255.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p268_p255.wav"></audio></div>
        
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p270.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p270_p268.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p270_p268.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p280.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-spk/p280_p255.wav"></audio></div>    
        <div class="grid-item"><audio controls src="cross-same-domain/spk-spk/p280_p255.wav"></audio></div>

    </div>

    <h3> Singing conversions audio ouputs from AutoVC models pretrained on either speech (column 2) or singing (column 3) data.</h3>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Converted voice with speech pretraining</div>
        <div class="grid-item head">Converted voice with singing pretraining</div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1174863894.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1174863894_1174863894.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1174863894_1174863894.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1143441144.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1143441144_1102104435.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1143441144_1102104435.wav"></audio></div>
        
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1141223094.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1141223094_1143441144.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1141223094_1143441144.wav"></audio></div>

        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1102104435.wav"></audio></div>
        <div class="grid-item"><audio controls src="cross-same-domain/spk-sng/1102104435_1141223094.wav"></audio></div>    
        <div class="grid-item"><audio controls src="cross-same-domain/sng-sng/1102104435_1141223094.wav"></audio></div>

    </div>

    <h2> Upperbound quality, as dictated by spectrogram-to-waveform synthesis process</h2>

    <p>To illustrate the upperbound limit for quality of our generated audio, the table below presents examples where audio recordings have been converted to mel spectrograms and resynthesized into audio using the pretrained Wavenet vocoder.
        This demonstrates the artefacts and deterioration due to resynthesis alone, and therefore provides an indication of the upperbound audio quality that other audio clips can be compared against for reference:</p>

    <div class="grid-container2">
        <div class="grid-item head">Original</div>
        <div class="grid-item head">Resynthesized</div>      
        <div class="grid-item"><audio controls src="1295/m9_arpeggios_straight_u_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/m9_arpeggios_straight_u_wvnt.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f2_arpeggios_straight_e_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f2_arpeggios_straight_e_wvnt.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f9_arpeggios_vocal_fry_a_org.mp3"></audio></div>
        <div class="grid-item"><audio controls src="1295/f9_arpeggios_vocal_fry_a_wvnt.mp3"></audio></div>
    </div>
    
    <h2>Spoken Voice Conversion with/without latent regressor loss</h2>

    <h3>Model condition: VCTK-BN</h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that used the bottleneck latent regressor loss,
        and was trained for 100,000 training steps on a quarter of the VCTK dataset.
        The input data was in a mel-spectrogram format.
        It was conditioned on voice identity embeddings (VIEs) from an encoder that was pretrained on the LibriSpeech and VoxCeleb1 datasets.
        The table shown below is arranged to present a comparison between source vocalist, target vocalist and converted voice singing clips, generated by this model:
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>

    <h3>Model: VCTK</h3>

    <p> For comparison, the audio files presented in this next table below come from an AutoVC model that was trained under the same conditions as the aforementioned model,
        but instead only used the reconstruction loss in its objective function. It can be heard from these examples, that the output audio is significantly less distorted or ambiguous in timbre.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p225_p226.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p226.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p226_p227.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p227.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p227_p228.wav"></audio></div>

        <div class="grid-item"><audio controls src="vctk_orgs/p228.wav"></audio></div>
        <div class="grid-item"><audio controls src="vctk_orgs/p225.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-vctk0.25_Vie-LibVox_100kSteps/p228_p225.wav"></audio></div>    

    </div>

    <h2> SVC with Different Features</h2>

    <p>
        So listener's can compare the quality between WORLD and mel-spectrogram feature-based SVC models, we present the resulting generated audio for each condition below. This has not been documented in the research, but is provided for researchers who might be curious about the acuostic comparison between audio files generated from either condition.
    </p>

    <h3> SVC with WORLD features </h3>

    <p> The audio files presented in the table below have been generated by an AutoVC network that took WORLD spectral envelope features as input, using only reconstruction loss. The VIE encoder that was trained on the entire DAMP datasets.
        This AutoVC network was trained for 100,000 training steps on a quarter of the DAMP dataset. As the model has not been sufficiently trained, features in the audio not exclusively related to voice identity have also been converted, such as the microphone or room's frequency responses of the target singers.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-dampWorld0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div> 

    <h3> SVC with Mel-spectrogram features </h3>

    <p> For comparison, the audio files presented in this next table below have been generated by a model trained under the same conditions as the SVC model mentioned above, except for the fact that its input features which were mel-spectrograms instead of WORLD features.
    </p>
        

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/426780220_1027314259.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1027314259.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1027314259_1050554650.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1050554650.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1050554650_1615650453.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1615650453.wav"></audio></div>
        <div class="grid-item"><audio controls src="damp_orgs/426780220.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconOnly-damp0.25_Vie-damp_100kSteps/1615650453_426780220.wav"></audio></div>

    </div>

    <h3> Models trained for 500k steps (evaluated with listening tests and objective metrics, as detialed in the paper) </h3>

    <p> The audio files presented in the remaining two tables below have been generated by AutoSVC networks as described in the paper, trained for 500,000 steps on a quarter of the DAMP dataset. <!-- Unlike in most demonstrations of voice identity conversion, the source audio here only represents the singer while the converted audio will come from a different utterance of theirs. -->
    </p>
        
    <p> The table below presents converted audio synthesized a version of the AutoSVC mode using only a reconstruction loss, and a VIE encoder that was pretrained on the DAMP dataset
    </p>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/148000577_1608346293_175.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_F148000577_timestep175_M473926181_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_F148000577_timestep175_M473926181.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/415267637_1591722196_3329.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_F415267637_timestep3329_F157931057_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_F415267637_timestep3329_F157931057.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/148187151_1864793464_1090.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_M148187151_timestep1090_M1224586431_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_M148187151_timestep1090_M1224586431.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/475351623_1840755102_7096.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_M475351623_timestep7096_F562082160_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M---Sng_M475351623_timestep7096_F562082160.wav"></audio></div>    

    </div>
   
    <p> The table below presents converted audio synthesized a version of the AutoSVC mode using a reconstruction and bottleneck latent regressor loss, and a VIE encoder that was pretrained on the DAMP dataset
    </p>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/454032310_2153157729_1638.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F454032310_timestep1638_F302211135_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F454032310_timestep1638_F302211135.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1377926800_1627187072_3665.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F1377926800_timestep3665_M167018645_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_F1377926800_timestep3665_M167018645.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/473926181_1927111247_827.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M473926181_timestep827_M475351623.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1654991314_2350788769_5102.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1654991314_timestep5102_F1456702500_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-C-Sng_M1654991314_timestep5102_F1456702500.wav"></audio></div>    

    </div>


    <p> The table below presents converted audio synthesized by the described model above, using a reconstruction and VIE regressor loss, and a VIE encoder that was pretrained on the DAMP dataset
    </p>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/197252304_1947611737_6548.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_F197252304_timestep6548_M1040413288_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_F197252304_timestep6548_M1040413288.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/433545629_2021841694_4632.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_F433545629_timestep4632_F1351135537_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_F433545629_timestep4632_F1351135537.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1385966031_1642413762_13029.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_M1385966031_timestep13029_F537048662_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_M1385966031_timestep13029_F537048662.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1482667809_1825196385_5428.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_M1482667809_timestep5428_M475351623_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="listening_study_stimuli/autoVc-ReconBnLrLoss-damp0.25_Vie-damp_500kSteps/M-E-Sng_M1482667809_timestep5428_M475351623.wav"></audio></div>    

    </div>

    <p> The table below presents converted audio synthesized by the described model above, using a reconstruction and bottleneck latent regressor loss, and a VIE encoder that was pretrained on the LibriSpeech and VoxCeleb1 datasets.
    </p>

    <div class="grid-container3">
        <div class="grid-item head">Source voice original audio</div>
        <div class="grid-item head">Target voice original audio</div>   
        <div class="grid-item head">Converted voice audio</div>

        <div class="grid-item"><audio controls src="damp_orgs/800175769_2104607575_1136.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F800175769_timestep1136_M792755197_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F800175769_timestep1136_M792755197.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1209787220_2149964507_7520.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F1209787220_timestep7520_F1118781094_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_F1209787220_timestep7520_F1118781094.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/819000103_2070957550_7792.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M819000103_timestep7792_F1288160835_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M819000103_timestep7792_F1288160835.wav"></audio></div>

        <div class="grid-item"><audio controls src="damp_orgs/1294358700_1651203139_2291.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1294358700_timestep2291_M493593861_target.wav"></audio></div>
        <div class="grid-item"><audio controls src="autoVc-ReconBnLrLoss-damp0.25_Vie-LibVox_500kSteps/M-C-Spk_M1294358700_timestep2291_M493593861.wav"></audio></div>    

    </div>

</body>
</html>
